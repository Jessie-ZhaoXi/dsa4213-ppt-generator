{"data/Figure_1_0.png": "Introduction of the Transformer Model Architecture", "data/Figure_2_0.png": "Implementation of Multi-Head Attention", "data/Figure_2_1.png": "Implementation of Multi-Head Attention"}