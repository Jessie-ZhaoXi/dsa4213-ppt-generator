{"data/Figure_1_0.png": "Introduction of the Transformer architecture.", "data/Figure_2_0.png": "Utilization of attention mechanisms exclusively.", "data/Figure_2_1.png": "Utilization of attention mechanisms exclusively."}